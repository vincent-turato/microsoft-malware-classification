# coding: utf-8
import os

import numpy as np
import pandas as pandas
from scipy import sparse
from sklearn.decomposition import NMF
from sklearn.externals import joblib
from sklearn.feature_extraction.text import TfidfVectorizer

import paths


def getEntropy(X):
    entropy = np.zeros(len(X))
    for i in range(len(X)):
        x = X[i]*1.0 / (sum(X[i]) + 0.00001)
        entropy[i] = -np.sum(x * np.log(x + 0.00000001))
    return entropy

def fileRead(filename):
    fin = open(filename, 'r')
    contents = []
    for line in fin:
        contents.append(line.strip())
    return contents


print "Packing features. This may take several minutes."
trainLabels = pandas.read_csv(paths.trainLabels)
submissionSample = pandas.read_csv(paths.sampleSubmissionFile)

# filesize
# train
xSizesTrain = np.zeros([len(trainLabels), 2])
for i,row in trainLabels.iterrows():
    malwareName = row['Id']
    if os.path.isfile('{}{}.bytes'.format(paths.trainDirectory, malwareName)):
        if os.path.isfile('{}{}.asm'.format(paths.trainDirectory, malwareName)):
            curSizeBytes = os.path.getsize('{}{}.bytes'.format(paths.trainDirectory, malwareName))
            curSizeAsm = os.path.getsize('{}{}.asm'.format(paths.trainDirectory, malwareName))
            xSizesTrain[i, 0] = curSizeBytes
            xSizesTrain[i, 1] = curSizeAsm

newaxis = np.newaxis

#test
xSizesTest = np.zeros([len(submissionSample), 2])
for i,row in submissionSample.iterrows():
    malwareName = row['Id']
    if os.path.isfile('{}{}.bytes'.format(paths.testDirectory, malwareName)):
        if os.path.isfile('{}{}.asm'.format(paths.testDirectory, malwareName)):
            xSizesTest[i, 0] = os.path.getsize('{}{}.bytes'.format(paths.testDirectory, malwareName))
            xSizesTest[i, 1] = os.path.getsize('{}{}.asm'.format(paths.testDirectory, malwareName))


#instruction frequency
malwareSampleFileNames = fileRead('{}instruction_frequency/fnames'.format(paths.featuresDirectory))
asmMalwareSamplesDict = {}
asmInstructions = ['jmp', 'mov', 'retf', 'push', 'pop', 'xor', 'retn', 'nop', 'sub', 'inc', 'dec', 'add',
                'imul', 'xchg', 'or', 'shr', 'cmp', 'call', 'shl', 'ror', 'rol', 'jnb']
for instruction in asmInstructions:
    values = fileRead('{}instruction_frequency/{}'.format(paths.featuresDirectory, instruction))
    for malwareName, val in zip(malwareSampleFileNames, values):
        asmMalwareSamplesDict[malwareName] = asmMalwareSamplesDict.get(malwareName, {})
        asmMalwareSamplesDict[malwareName][instruction] = val
# train
xAsmTrain = np.zeros((len(trainLabels), 22))
for i, malwareName in enumerate(trainLabels.Id.values):
    for j, instruction in enumerate(asmInstructions):
        if os.path.isfile('{}{}.bytes'.format(paths.trainDirectory, malwareName)):
            if os.path.isfile('{}{}.asm'.format(paths.trainDirectory, malwareName)):
                xAsmTrain[i, j] = asmMalwareSamplesDict[malwareName][instruction]

eAsmTr = getEntropy(xAsmTrain)

#test
xAsmTest = np.zeros((len(submissionSample), 22))
for i, malwareName in enumerate(submissionSample.Id.values):
    for j, instruction in enumerate(asmInstructions):
        if os.path.isfile('{}{}.bytes'.format(paths.testDirectory, malwareName)):
            if os.path.isfile('{}{}.asm'.format(paths.testDirectory, malwareName)):
                xAsmTest[i, j] = asmMalwareSamplesDict[malwareName][instruction]

eAsmTest = getEntropy(xAsmTest)



#line counts
malwareSampleFileNames = fileRead('{}instruction_frequency/fnames'.format(paths.featuresDirectory))
lineCounts = fileRead('{}instruction_frequency/line_count'.format(paths.featuresDirectory))

lineCountMalwareDict = {}
for i, malwareName in enumerate(malwareSampleFileNames):
    lineCountMalwareDict[malwareName] = lineCounts[i]

# train
xLineCountTrain = np.zeros((len(trainLabels), 1))
for i, malwareName in enumerate(trainLabels.Id.values):
    if os.path.isfile('{}{}.bytes'.format(paths.trainDirectory, malwareName)):
        if os.path.isfile('{}{}.asm'.format(paths.trainDirectory, malwareName)):
            xLineCountTrain[i, 0] = lineCountMalwareDict[malwareName]

eLineCountTrain = getEntropy(xLineCountTrain)

# test
xLineCountTest = np.zeros((len(submissionSample), 1))
for i, malwareName in enumerate(submissionSample.Id.values):
    if os.path.isfile('{}{}.bytes'.format(paths.testDirectory, malwareName)):
        if os.path.isfile('{}{}.asm'.format(paths.testDirectory, malwareName)):
            xLineCountTest[i, 0] = lineCountMalwareDict[malwareName]

eLineCountTest = getEntropy(xLineCountTest)


# import calls
def get_call_list(fname):
    stdCalls = []
    if os.path.isfile(fname):
        lines = fileRead(fname)
        for line in lines:
            stdCalls.append(line.split('__stdcall')[1].split('(')[0].split('_')[0].strip())
    return stdCalls

# train
stdCallTxtTrain = []
for i,row in trainLabels.iterrows():
    stdCallTxtTrain.append(' '.join(get_call_list('{}stdcall_grepper/'.format(paths.featuresDirectory) + row['Id'])))

# train
stdCallTxtTest = []
for i,row in submissionSample.iterrows():
    stdCallTxtTest.append(' '.join(get_call_list('{}stdcall_grepper/'.format(paths.featuresDirectory) + row['Id'])))


vect = TfidfVectorizer(max_features=10000)
vect.fit(stdCallTxtTrain + stdCallTxtTest)
xStdCallTrain = vect.transform(stdCallTxtTrain)
xStdCallTest = vect.transform(stdCallTxtTest)





nmf = NMF(n_components=10)
nmf.fit(sparse.vstack([xStdCallTrain, xStdCallTest]))
xStdCallsNmfTrain = nmf.transform(xStdCallTrain)
xStdCallsNmfTest = nmf.transform(xStdCallTest)

# building
X_train_tr = np.hstack((
                          # X_lines_tr,
                          # size_ratio_tr,
    xAsmTrain,
    xSizesTrain,  #!
    # E_lines_tr[:, np.newaxis], #!
    xStdCallsNmfTrain,
                          ))

X_train_te = np.hstack((
                          # X_lines_te,
                          # size_ratio_te,
    xAsmTest,
    xSizesTest,  #!
    # E_lines_te[:, np.newaxis], #!
    xStdCallsNmfTest,
                          ))

# dump
joblib.dump((X_train_tr, X_train_te), '{}X_basepack'.format(paths.featuresDirectory))

print 'Success'
